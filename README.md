# V2A

This is repository with dataset and dataset generation code for [V2A - Vision to Action: Learning robotic arm actions based on vision and language](https://openaccess.thecvf.com/content/ACCV2020/papers/Nazarczuk_V2A_-_Vision_to_Action_Learning_robotic_arm_actions_based_ACCV_2020_paper.pdf).

## Dataset

To download a dataset please use the followink [link](https://imperialcollegelondon.box.com/s/v9sfaul0s4ne86vobfyfpsior2ry1xt3).

The link provides a `.zip` file with V2A instructions for the corresponding splits of [SHOP-VRB](https://michaal94.github.io/SHOP-VRB/) dataset. Files with `_GT` in the name contatin additional filed with suggested ground truth sequence of primitive actions for the given instruction.

## Dataset generation
Code for dataset generation will appear here soon

### Citation

**[V2A - Vision to Action: Learning robotic arm actions based on vision and language](https://openaccess.thecvf.com/content/ACCV2020/papers/Nazarczuk_V2A_-_Vision_to_Action_Learning_robotic_arm_actions_based_ACCV_2020_paper.pdf)**
<br>
Michal Nazarczuk, 
Krystian Mikolajczyk
<br>
Imperial College London
<br>
In Proceedings of the Asian Conference on Computer Vision (*ACCV*) 2020.
<br>

```
@inproceedings{nazarczuk2020v2a,
  title={V2A - Vision to Action: Learning robotic arm actions based on vision and language},
  author={Nazarczuk, Michal and Mikolajczyk, Krystian},
  booktitle={Proceedings of the Asian Conference on Computer Vision (ACCV)},
  year={2020}
}
```
